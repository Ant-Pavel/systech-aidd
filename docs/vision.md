# Техническое видение проекта

## 1. Технологии

### Основные технологии
- **Python 3.11+** - основной язык разработки
- **uv** - управление зависимостями и виртуальным окружением
- **aiogram 3.x** - фреймворк для Telegram Bot API (метод polling)
- **openai** (официальный клиент) - для работы с LLM через провайдер Openrouter
- **make** - автоматизация сборки и запуска проекта

### Вспомогательные библиотеки
- **python-dotenv** - загрузка переменных окружения из .env файла

### Хранение данных
- **В памяти** - история диалогов хранится в оперативной памяти (для MVP)

## 2. Принципы разработки

### Основные принципы
- **KISS (Keep It Simple, Stupid)** - максимальная простота, никакого оверинжиниринга
- **ООП** - строго 1 класс = 1 файл
- **Разделение ответственности** - каждый класс решает одну конкретную задачу
- **Явное лучше неявного** - понятный, читаемый код

### Подход к коду
- Async/await - асинхронное программирование (в соответствии с aiogram)
- Без type hints - простота и скорость разработки MVP
- Без юнит-тестов на этапе MVP - тестирование вручную
- Без линтеров на этапе MVP
- Минимум зависимостей между модулями

### Обработка ошибок
- Простое логирование ошибок в консоль
- Graceful degradation - бот продолжает работать при ошибках отдельных запросов
- Понятные сообщения пользователю при ошибках

## 3. Структура проекта

```
systech-aidd/
├── src/
│   ├── bot.py              # Главный класс бота (aiogram)
│   ├── llm_client.py       # Класс для работы с LLM через Openrouter
│   ├── message_handler.py  # Обработка сообщений пользователя
│   ├── conversation.py     # Класс для хранения истории диалога
│   └── config.py           # Класс конфигурации приложения
├── main.py                 # Точка входа в приложение
├── .env.example            # Пример файла с переменными окружения
├── .env                    # Файл с переменными окружения (в .gitignore)
├── pyproject.toml          # Конфигурация uv и зависимости
├── Makefile                # Команды для сборки и запуска
├── docs/                   # Документация проекта
└── README.md               # Инструкции по запуску
```

### Основные модули

- **bot.py** - инициализация aiogram бота, запуск polling
- **llm_client.py** - взаимодействие с Openrouter через openai клиент
- **message_handler.py** - обработка входящих сообщений от пользователя
- **conversation.py** - класс для управления историей диалога (в памяти, ключ: user_id + chat_id)
- **config.py** - класс для загрузки и хранения конфигурации из .env

### Принцип организации
- 1 класс = 1 файл
- Каждый модуль отвечает за одну задачу
- Минимум зависимостей между модулями

## 4. Архитектура проекта

### Схема взаимодействия компонентов

```
User (Telegram) 
    ↓
Bot (aiogram) 
    ↓
MessageHandler ← Conversation
    ↓               (история)
LLMClient
    ↓
Openrouter API
```

### Поток обработки сообщения

1. **User** отправляет сообщение в Telegram
2. **Bot** получает сообщение через aiogram (polling)
3. **Bot** передает сообщение в **MessageHandler**
4. **MessageHandler** получает историю из **Conversation** по ключу (user_id, chat_id)
5. **MessageHandler** формирует запрос к **LLMClient** (контекст + текущее сообщение)
6. **LLMClient** отправляет запрос в Openrouter и получает ответ
7. **MessageHandler** сохраняет диалог в **Conversation**
8. **Bot** отправляет ответ пользователю

### Классы и их ответственность

- **Config** - хранит настройки (токены, модель LLM, лимиты и т.д.)
- **Bot** - точка входа, инициализация aiogram, регистрация хендлеров
- **MessageHandler** - координирует обработку сообщения
- **Conversation** - хранит и управляет историей диалогов (последние 10 сообщений)
- **LLMClient** - отправляет запросы к LLM API

### Команды бота

- **/start** - приветствие и инструкция
- **/clear** - очистка истории диалога
- Любое текстовое сообщение - обработка через LLM

## 5. Модель данных

### Структура сообщения

Формат совместим с OpenAI API:
```python
{
    "role": "user" | "assistant",
    "content": "текст сообщения"
}
```

### Хранение истории диалогов

```python
# Структура в памяти
conversations = {
    (user_id, chat_id): [
        {"role": "user", "content": "привет"},
        {"role": "assistant", "content": "Здравствуйте! Чем могу помочь?"},
        ...
    ]
}
```

### Класс Conversation

**Методы:**
- `add_message(user_id, chat_id, role, content)` - добавить сообщение в историю
- `get_history(user_id, chat_id)` - получить последние 10 сообщений
- `clear_history(user_id, chat_id)` - очистить историю диалога

**Логика:**
- Ключ: кортеж (user_id, chat_id)
- Значение: список сообщений (максимум 10)
- При добавлении нового сообщения удаляются самые старые, если превышен лимит

## 6. Работа с LLM

### Класс LLMClient

**Основной метод:**
- `get_response(messages)` - отправить массив сообщений и получить ответ от LLM

**Реализация:**
- Использование официального клиента `openai` с настройкой на Openrouter
- Base URL: `https://openrouter.ai/api/v1`
- Передача API ключа Openrouter через заголовки

### Формат запроса

```python
# Отправляем историю диалога
messages = [
    {"role": "user", "content": "привет"},
    {"role": "assistant", "content": "Здравствуйте!"},
    {"role": "user", "content": "как дела?"}
]
```

### Параметры по умолчанию

- **model**: `anthropic/claude-3.5-sonnet` (Claude Sonnet 4.5)
- **messages**: история диалога из Conversation
- **temperature**: `0.7` (баланс между креативностью и последовательностью)
- **max_tokens**: `1000` (достаточно для развернутых ответов)

### Обработка ошибок

- При ошибке API - логирование и возврат сообщения об ошибке
- Таймаут запроса: 30 секунд
- Простое сообщение пользователю: "Извините, произошла ошибка. Попробуйте еще раз."

## 7. Сценарии работы

### Сценарий 1: Первый запуск

1. Пользователь отправляет `/start`
2. Бот отвечает приветствием и краткой инструкцией
3. Пользователь начинает диалог

### Сценарий 2: Обычный диалог

1. Пользователь отправляет текстовое сообщение
2. Бот показывает индикатор "печатает..."
3. Бот получает историю диалога (последние 10 сообщений)
4. Бот отправляет запрос в LLM с контекстом
5. Бот получает ответ и отправляет пользователю
6. Сообщения сохраняются в историю

### Сценарий 3: Помощь

1. Пользователь отправляет `/help`
2. Бот отправляет описание возможностей и команд

### Сценарий 4: Очистка истории

1. Пользователь отправляет `/clear`
2. Бот удаляет всю историю диалога для этого пользователя
3. Бот подтверждает очистку сообщением
4. Следующий диалог начинается с чистого листа

### Сценарий 5: Обработка ошибок

1. Пользователь отправляет сообщение
2. Происходит ошибка при запросе к LLM
3. Бот логирует ошибку в консоль
4. Бот отправляет пользователю понятное сообщение об ошибке
5. История не сохраняется (можно повторить запрос)

## 8. Подход к конфигурированию

### Класс Config

**Реализация:**
- Загрузка переменных окружения через `python-dotenv` из `.env` файла
- Простая валидация обязательных параметров (проверка на None)
- Значения по умолчанию для необязательных параметров
- Доступ к настройкам через атрибуты класса

### Переменные окружения

```bash
# Telegram Bot
TELEGRAM_BOT_TOKEN=your_telegram_bot_token

# Openrouter API
OPENROUTER_API_KEY=your_openrouter_api_key

# LLM Settings (опциональные, есть значения по умолчанию)
LLM_MODEL=anthropic/claude-3.5-sonnet
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=1000
LLM_TIMEOUT=30

# Conversation (опционально)
MAX_HISTORY_MESSAGES=10
```

### Валидация

- **Обязательные**: `TELEGRAM_BOT_TOKEN`, `OPENROUTER_API_KEY`
- **Опциональные**: все остальные (используются значения по умолчанию)
- При отсутствии обязательных параметров - ошибка при запуске

### Файл .env.example

- Содержит шаблон всех переменных окружения
- Пользователь копирует в `.env` и заполняет своими значениями
- `.env` добавлен в `.gitignore`

## 9. Подход к логгированию

### Реализация

**Используем стандартный модуль `logging` Python:**
- Вывод логов в консоль (stdout)
- Формат: `[TIMESTAMP] [LEVEL] [MODULE] - MESSAGE`
- Уровень по умолчанию: `INFO`
- Настройка логгера при запуске приложения

### Что логируем

**INFO уровень:**
- Запуск бота
- Получение сообщения от пользователя (user_id, chat_id, текст сообщения)
- Отправка запроса к LLM (количество сообщений в контексте)
- Получение ответа от LLM (текст ответа)
- Успешная отправка ответа пользователю
- Выполнение команд (/start, /clear, /help)

**ERROR уровень:**
- Ошибки при запросе к LLM API (детали ошибки)
- Ошибки конфигурации при запуске
- Неожиданные исключения (stacktrace)

### Пример логов

```
[2025-10-10 12:00:00] [INFO] [bot] - Bot started successfully
[2025-10-10 12:00:15] [INFO] [message_handler] - Received message from user 123456 in chat 789012: "Привет"
[2025-10-10 12:00:16] [INFO] [llm_client] - Sending request to LLM with 1 messages
[2025-10-10 12:00:18] [INFO] [llm_client] - Received response: "Здравствуйте! Чем могу помочь?"
[2025-10-10 12:00:18] [INFO] [message_handler] - Response sent to user 123456
[2025-10-10 12:01:00] [ERROR] [llm_client] - LLM API error: Request timeout after 30s
```

### Особенности

- Простота: никаких файлов, ротации логов, только консоль
- Все важные события фиксируются для отладки
- Содержимое сообщений логируется для понимания контекста ошибок
- При необходимости можно перенаправить stdout в файл через shell

